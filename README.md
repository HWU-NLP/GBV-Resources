# GBV-Resources
A repository of resources for automated identification of online Gender-Based Violence and related phenomena.

For futher details, see:

Gavin Abercrombie, Aiqi Jiang, Poppy Gerrard-Abbott, Ioannis Konstas, and Verena Rieser. 2023. Resources for Automated Identification of Online Gender-Based Violence: A Systematic Review. Proceedings of the 7th Workshop on Online Abuse and Harms (WOAH). Association for Computational Linguistics.


#### Datasets


| Reference | Title | Dataset URL | GBV characterisation | Platform | Language | Modality | Sampling | Date of data | Annotators | IRB | Perspec- tivism | Data Statement |
|:----- |:----- |:----- |:----- | :----- | :----- | :----- | :----- | :----- | :----- | :----- | :----- | :----- |
| [Al-Hassan and Al-Dossari, 2022](https://link.springer.com/article/10.1007/s00530-020-00742-w) | Detection of hate speech in Arabic tweets using deep learning  | N/A | *Sexism* | Twitter | Arabic | Text | Keywords | N/A | 2 volunteers | No | No | No |
| [Almanea and Poesio, 2022](https://aclanthology.org/2022.lrec-1.244/) | ArMIS - The Arabic Misogyny and Sexism Corpus with Annotator Subjective Disagreements | https://codalab.lisn.upsaclay.fr/competitions/6146#learn_the_details-get_starting_kit | *Misogyny*, *Sexism* | Twitter | Arabic | Text | Keywords | October 2020 | 3 main annotators and 32 others. Self-defined beliefs and gender | No | Yes | No |
| [Alsafari et al., 2020](https://www.sciencedirect.com/science/article/pii/S2468696420300379) | Hate and offensive speech detection on Arabic social media | https://github.com/sbalsefri/ArabicHateSpeechDataset | *Gender* as category | Twitter | Arabic (Gulf) | Text | keywords, hashtags, profiles | April - September 2019 | 3: 2 women, 1 man | No | No | No |
|[Anzovino et al., 2018](https://link.springer.com/chapter/10.1007/978-3-319-91947-8_6) | Automatic Identification and Classification of Misogynistic Language on Twitter | https://amievalita2018.wordpress.com/data/ | *Misogyny* | Twitter | English | Text | keywords, hashtags, mentions of potential harassed users, self-declared mysoginist profiles | 2017 | 3 experts + crowdworkers | No | No | Yes |
| [Assenmacher et al., 2021](https://www.researchgate.net/profile/Marco-Niemann/publication/356902512_RP-Mod_RP-Crowd_Moderator-_and_Crowd-Annotated_German_News_Comment_Datasets/links/61b20092bec354609d61fadc/RP-Mod-RP-Crowd-Moderator-and-Crowd-Annotated-German-News-Comment-Datasets.pdf) | RP-Mod & RP-Crowd: Moderator- and Crowd-Annotated German News Comment Datasets | https://zenodo.org/record/5291339#.Y6RfyOLP3S6 | *Sexism* | Rheinische Post | German | Text | Comments blocked by community managers | Nov. 2018 - June 2020 | 5 per item | No | No | No |
| [Basile et al., 2019](https://aclanthology.org/S19-2007/) | SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter | https://competitions.codalab.org/competitions/19935 | *Women* as target | Twitter | English, Spanish | Text | Victims of hate accounts; identified haters; keywords | July 2018 - Sept. 2018 + from earlier datasets | Crowdworkers | No | No | No |
| [Bhattacharya et al., 2020](https://aclanthology.org/2020.trac-1.25/) | Developing a Multilingual Annotated Corpus of Misogyny and Aggression | https://sites.google.com/view/trac2/shared-task?pli=1 | *Misogyny* | Facebook, Twitter, YouTube | Bangla, English, Hindi, code-mixed | Text | Topics | Unknown | 4 linguists 'expected to have a centrist or left-leaning political orientation' |  | No | No | No |
| [Borkan et al., 2019](https://dl.acm.org/doi/10.1145/3308560.3317593) | Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification | https://www.tensorflow.org/datasets/catalog/civil_comments | *Gender* as category, subgroups: *Male*, *Female*, *Transgender*, *Other gender* | Comment forums | English | Text | Unknown | Crowdworkers | Unknown | No | No | No |
| [Bosco et al.](https://ceur-ws.org/Vol-2263/paper010.pdf) | Overview of the EVALITA 2018 Hate Speech Detection Task | http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html | *'Gender issues'*-based hate | Facebook, Twitter | Italian | Text | Facebook: targeted pages and groups; Twitter: keywords | Facebook: 2016; Twitter 2017-2018 | Facebook: bachelor students; Twitter: experts and crowdworkers | No | No | No |
| [Cercas Curry et al., 2021](https://aclanthology.org/2021.emnlp-main.587/) | ConvAbuse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in Conversational AI | https://github.com/amandacurry/convabuse | *Sexism*, *sexual harrassment* | Dialogue systems: ELIZA, CarbonBot (Facebook) | English | Text | Stratified keyword | CarbotBot: Oct. 2019 - Dec. 2020; ELIZA: Dec. 2002 - Nov. 2007 | 6 female and 2 non-binary Gender Studies students | Yes | Yes | Yes |
| [Chiril et al., 2021](https://aclanthology.org/2021.findings-emnlp.242/) | "Be nice to your wife! The restaurants are closed": Can Gender Stereotype Detection Improve Sexism Classification? | https://bit.ly/FrenchGenderStereotypes | *Sexism* | Twitter | French | Text | Keywords, personal names, hashtags | Unknown | 1 male, 1 female students in Linguistics and Communication and Gender | No | No | No |
| [Chiril et al., 2019](https://aclanthology.org/2019.jeptalnrecital-court.21/) | Multilingual and Multitarget Hate Speech Detection in Tweets | N/A | *Sexism* | Twitter | 2 female and 1 male students in Communication and Gender | French | Text | Oct. 2017 - May 2018 | Keywords | No | No | No |
| [Chiril et al. 2020](https://aclanthology.org/2020.lrec-1.175/) | An Annotated Corpus for Sexism Detection in French Tweets | https://github.com/patriChiril/An-Annotated-Corpus-for-Sexism-Detection-in-French-Tweets | *Sexism* | Twitter | French | Text | Keywords, hashtags, personal names | Oct. 2017 - May 2018 | 3 female and 2 male Communication and Gender students | No | No | No |
| [Chung and Lin, 2021](https://ieeexplore.ieee.org/document/9598528) | TOCAB: A Dataset for Chinese Abusive Language Processing | http://nlp.cse.ntou.edu.tw/resources/TOCAB/ | *Sex*  (*gender*, *sexual orientation*, or *gender identity*) as abuse category | PTT (Taiwanese bulletin board) | Chinese | Text | Popular posts | Mar. 2019 - June 2019 | 12 students | No | No | No |
| [Das et al., 2022](https://aclanthology.org/2022.aacl-main.23/) | Hate Speech and Offensive Language Detection in Bengali | https://github.com/hate-alert/Bengali_Hate | *Gender* as target | Twitter | Bengali | Text | Keywords | Unknown | 4 Computer Science students | No | No | No |
| [El Ansari et al., 2020](https://link.springer.com/chapter/10.1007/978-3-030-51935-3_14) | A Dataset to Support Sexist Content Detection in Arabic Text | N/A | *Sexism*, *discrimination and Violence Against Women* | Twitter | Arabic | Text | Keywords |  2018 | Volunteers | No | No | No |
| [Fanton et al., 2021](https://aclanthology.org/2021.acl-long.250/) | Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech |https://github.com/marcoguerini/CONAN | *Women* as target | Semi-synthetic text | English | Text | Unknown | Unknown | 3 student interns | No | No | No |
| [Fersini et al., 2018](https://ceur-ws.org/Vol-2150/overview-AMI.pdf) | Overview of the Task on Automatic Misogyny Identification at IberEval 2018 | https://amiibereval2018.wordpress.com/important-dates/data/ | *Misogyny* | Twitter | English Spanish | Text | Keywords | July 2017 - Nov. 2017 | Unknown + crowdworkers | No | No | No |
| [Fersini et al., 2020](https://ceur-ws.org/Vol-2765/paper161.pdf) | AMI @ EVALITA2020: Automatic Misogyny Identification | https://github.com/dnozza/ami2020 | *Misogyny* | Twitter | Italian | Text | Unknown | 2018 + 2020 | Unknown | No | No | No |
| [Fersini et al., 2022](https://aclanthology.org/2022.semeval-1.74.pdf) | SemEval-2022 Task 5: Multimedia Automatic Misogyny Identification | https://competitions.codalab.org/competitions/34175 | *Misogyny* | Twitter, Reddit;  meme sites e.g., 9GaG, Knowyourmeme, Imgur | English | Memes | Threads with women as the subject; anti-women accounts; (3) target victim accounts; (4) keywords and hashtags | Unknown | Unknown | No | No | No | 
| [García-Díaz et al., 2021](https://www.sciencedirect.com/science/article/pii/S0167739X20301928) | Detecting misogyny in Spanish tweets. An approach based on linguistics features and word embeddings | https://pln.inf.um.es/corpora/misogyny/misocorpus-spanish-2020.rar | *Misogyny* | Twitter | Spanish | Text | Target accounts; geographical locations; keywords | Unknown | 5 women, 2 men:  authors, 2 colleagues, 1 student | No | No | No | 
| [Gomez et al., 2021](https://ieeexplore.ieee.org/abstract/document/9093414) | Exploring hate speech detection in multimodal publications | https://drive.google.com/file/d/1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF | *Sexism* | Twitter | English | Image + text | Keywords | Sept. 2018 - Feb. 2019 | 3 crowdworkers per item | No | No | No |  
| [Gong et al., 2021](https://ojs.aaai.org/index.php/AAAI/article/view/17738) |  Abusive Language Detection in Heterogeneous Contexts: Dataset Collection and the Role of Supervised Attention | N/A  | *Gender and sexuality* as target | YouTube | English |  Text | Keywords | 2017 | 17 psychology students, incl. 3 graduate students studying bullying and related phenomena | No | No | No | 
| [Grosz and Conde-Cespedes, 2020](https://hal.science/hal-02573576) | Automatic Detection of Sexist Statements Commonly Used at the Workplace | https://github.com/dylangrosz/Automatic_Detection_of_Sexist_Statements_Commonly_Used_at_the_Workplace | *Sexism* | Twitter, work-related quotes, press quotes, faculty/student submissions | English | Text | Keywords | Unknown | Authors: 1 male, 1 female | No | No | No | 
| [Guellil et al., 2021](https://arxiv.org/abs/2104.01443) | Sexism detection: The first corpus in Algerian dialect with a code-switching in Arabic/ French and English | N/A | *Sexism* | YouTube | Arabic (Algerian) | Text | Keywords and manually selected video IDs | Feb. - Mar. 2019 | 3 Algerian Arabic speakers | No | No | No |
| [Guest et al., 2021](https://aclanthology.org/2021.eacl-main.114/) | An Expert Annotated Dataset for the Detection of Online Misogyny | https://github.com/ellamguest/online-misogyny-eacl2021 | *Misogyny* | Reddit | English | Text | Targeted subreddits | Feb. - May 2020 | 6 annotators trained (by the authors) to identify misogynistic content | No | No | Yes |
| [Hewitt et al., 2016](https://dl.acm.org/doi/10.1145/2908131.2908183) | The problem of identifying misogynist language on Twitter (and other online social spaces) | N/A | *Misogyny* | Twitter | English | Text | Keywords | Unknown | 1 researcher | No | No | No |
| [Höfels et al., 2022](https://aclanthology.org/2022.lrec-1.243/) | CoRoSeOf - An Annotated Corpus of Romanian Sexist and Offensive Tweets | https://aclanthology.org/2022.lrec-1.243/ | *Sexism* | Twitter | Romanian | Text | Keywords | May - Sept. 2021 | 10: 7 female, 3 male students in Languages and Literature and Modern Applied Languages 'with an interest/knowledge in gender studies' | No | No | Partial | 
| [Ibrohim et al., 2019](https://aclanthology.org/W19-3506/) | Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter | https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection | *Hate based on gender* as category | Twitter | Indonesian | Text | Previous datasets + keywords | Mar. - Oct. 2018 + old data | 30 from different backgrounds. 3 per item. | No | No | No |
| [Jha and Mamidi, 2017](https://aclanthology.org/W17-2902/) | When does a compliment become sexist? Analysis and classification of ambivalent sexism using Twitter data | https://github.com/AkshitaJha/NLP_CSS_2017 | *Sexism* | Twitter | English | Text | Keywords | Unknown | Authors + 3 23-year old non-activist feminists | No | No | No |
| []() | | | | | | | | | | | |
| []() | | | | | | | | | | | |
| []() | | | | | | | | | | | |
| []() | | | | | | | | | | | |
